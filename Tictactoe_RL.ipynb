{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QPT_51IDeznI",
        "l6Rmf-6tKPin"
      ],
      "authorship_tag": "ABX9TyM3EoXTaxAwoW8oL52iiI7l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pronoma/Sutton-BartoSolutions/blob/main/Tictactoe_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Tic-Tac-Toe RL algorithm described by Sutton and Barto in Chapter 1 (2 learning agent version)"
      ],
      "metadata": {
        "id": "QPT_51IDeznI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B0bfB86wkpHs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BOARD_ROWS = 3\n",
        "BOARD_COLS = 3"
      ],
      "metadata": {
        "id": "osSX2L4Ck5Hy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Board State"
      ],
      "metadata": {
        "id": "KbFXHfrkewBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "    def __init__(self, p1, p2):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.p1 = p1\n",
        "        self.p2 = p2\n",
        "        self.isEnd = False\n",
        "        self.boardHash = None\n",
        "        # init p1 plays first\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    # get unique hash of current board state\n",
        "    def getHash(self):\n",
        "        self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return self.boardHash\n",
        "\n",
        "    def winner(self):\n",
        "        # row\n",
        "        for i in range(BOARD_ROWS):\n",
        "            if sum(self.board[i, :]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[i, :]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # col\n",
        "        for i in range(BOARD_COLS):\n",
        "            if sum(self.board[:, i]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[:, i]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # diagonal\n",
        "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
        "        diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)])\n",
        "        diag_sum = max(abs(diag_sum1), abs(diag_sum2))\n",
        "        if diag_sum == 3:\n",
        "            self.isEnd = True\n",
        "            if diag_sum1 == 3 or diag_sum2 == 3:\n",
        "                return 1\n",
        "            else:\n",
        "                return -1\n",
        "\n",
        "        # tie\n",
        "        # no available positions\n",
        "        if len(self.availablePositions()) == 0:\n",
        "            self.isEnd = True\n",
        "            return 0\n",
        "        # not end\n",
        "        self.isEnd = False\n",
        "        return None\n",
        "\n",
        "    def availablePositions(self):\n",
        "        positions = []\n",
        "        for i in range(BOARD_ROWS):\n",
        "            for j in range(BOARD_COLS):\n",
        "                if self.board[i, j] == 0:\n",
        "                    positions.append((i, j))  # need to be tuple\n",
        "        return positions\n",
        "\n",
        "    def updateState(self, position):\n",
        "        self.board[position] = self.playerSymbol\n",
        "        # switch to another player\n",
        "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
        "\n",
        "    # only when game ends\n",
        "    def giveReward(self):\n",
        "        result = self.winner()\n",
        "        # backpropagate reward\n",
        "        if result == 1:\n",
        "            self.p1.feedReward(1)\n",
        "            self.p2.feedReward(0)\n",
        "        elif result == -1:\n",
        "            self.p1.feedReward(0)\n",
        "            self.p2.feedReward(1)\n",
        "        else:\n",
        "            self.p1.feedReward(0.1)\n",
        "            self.p2.feedReward(0.5)\n",
        "\n",
        "    # board reset\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.boardHash = None\n",
        "        self.isEnd = False\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    def play(self, rounds=100):\n",
        "        for i in range(rounds):\n",
        "            if i % 1000 == 0:\n",
        "                print(\"Rounds {}\".format(i))\n",
        "            while not self.isEnd:\n",
        "                # Player 1\n",
        "                positions = self.availablePositions()\n",
        "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                # take action and upate board state\n",
        "                self.updateState(p1_action)\n",
        "                board_hash = self.getHash()\n",
        "                self.p1.addState(board_hash)\n",
        "                # check board status if it is end\n",
        "\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    # self.showBoard()\n",
        "                    # ended with p1 either win or draw\n",
        "                    self.giveReward()\n",
        "                    self.p1.reset()\n",
        "                    self.p2.reset()\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "                else:\n",
        "                    # Player 2\n",
        "                    positions = self.availablePositions()\n",
        "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                    self.updateState(p2_action)\n",
        "                    board_hash = self.getHash()\n",
        "                    self.p2.addState(board_hash)\n",
        "\n",
        "                    win = self.winner()\n",
        "                    if win is not None:\n",
        "                        # self.showBoard()\n",
        "                        # ended with p2 either win or draw\n",
        "                        self.giveReward()\n",
        "                        self.p1.reset()\n",
        "                        self.p2.reset()\n",
        "                        self.reset()\n",
        "                        break\n",
        "\n",
        "    # play with human\n",
        "    def play2(self):\n",
        "        while not self.isEnd:\n",
        "            # Player 1\n",
        "            positions = self.availablePositions()\n",
        "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "            # take action and upate board state\n",
        "            self.updateState(p1_action)\n",
        "            self.showBoard()\n",
        "            # check board status if it is end\n",
        "            win = self.winner()\n",
        "            if win is not None:\n",
        "                if win == 1:\n",
        "                    print(self.p1.name, \"wins!\")\n",
        "                else:\n",
        "                    print(\"tie!\")\n",
        "                self.reset()\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                # Player 2\n",
        "                positions = self.availablePositions()\n",
        "                p2_action = self.p2.chooseAction(positions)\n",
        "\n",
        "                self.updateState(p2_action)\n",
        "                self.showBoard()\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    if win == -1:\n",
        "                        print(self.p2.name, \"wins!\")\n",
        "                    else:\n",
        "                        print(\"tie!\")\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "    def showBoard(self):\n",
        "        # p1: x  p2: o\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            print('-------------')\n",
        "            out = '| '\n",
        "            for j in range(0, BOARD_COLS):\n",
        "                if self.board[i, j] == 1:\n",
        "                    token = 'x'\n",
        "                if self.board[i, j] == -1:\n",
        "                    token = 'o'\n",
        "                if self.board[i, j] == 0:\n",
        "                    token = ' '\n",
        "                out += token + ' | '\n",
        "            print(out)\n",
        "        print('-------------')"
      ],
      "metadata": {
        "id": "fIbPhxldk7en"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Player:\n",
        "\n",
        "    def __init__(self, name, exp_rate=0.3):\n",
        "        self.name = name\n",
        "        self.states = []  # record all positions taken\n",
        "        self.lr = 0.2\n",
        "        self.exp_rate = exp_rate\n",
        "        self.decay_gamma = 0.9\n",
        "        self.states_value = {}  # state -> value\n",
        "        self.exp_choice = 0\n",
        "\n",
        "    def getHash(self, board):\n",
        "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return boardHash\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        self.exp_choice = np.random.uniform(0, 1)\n",
        "        if self.exp_choice <= self.exp_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(positions))\n",
        "            action = positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for p in positions:\n",
        "                next_board = current_board.copy()\n",
        "                next_board[p] = symbol\n",
        "                next_boardHash = self.getHash(next_board)\n",
        "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
        "                # print(\"value\", value)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = p\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        self.states.append(state)\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        for st in reversed(self.states):\n",
        "            if self.states_value.get(st) is None:\n",
        "                self.states_value[st] = 0\n",
        "            if self.exp_choice >= self.exp_rate:\n",
        "                self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
        "            reward = self.states_value[st]\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "\n",
        "    def savePolicy(self):\n",
        "        fw = open('policy_' + str(self.name), 'wb')\n",
        "        pickle.dump(self.states_value, fw)\n",
        "        fw.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        fr = open(file, 'rb')\n",
        "        self.states_value = pickle.load(fr)\n",
        "        fr.close()\n"
      ],
      "metadata": {
        "id": "OBMtCTJ2lNJn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "ZNVXiscXehwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HumanPlayer:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def chooseAction(self, positions):\n",
        "        while True:\n",
        "            row = int(input(\"Input your action row:\"))\n",
        "            col = int(input(\"Input your action col:\"))\n",
        "            action = (row, col)\n",
        "            if action in positions:\n",
        "                return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        pass\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # training\n",
        "    p1 = Player(\"p1\")\n",
        "    p2 = Player(\"p2\")\n",
        "\n",
        "    st = State(p1, p2)\n",
        "    print(\"training...\")\n",
        "    st.play(5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzFUiNYrmyhd",
        "outputId": "91b8d7f3-45df-4918-bd7d-a9f370a56a4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n",
            "Rounds 0\n",
            "Rounds 1000\n",
            "Rounds 2000\n",
            "Rounds 3000\n",
            "Rounds 4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1.savePolicy()\n",
        "p2.savePolicy()"
      ],
      "metadata": {
        "id": "okeGzArPpWXp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1.loadPolicy(\"policy_p1\")"
      ],
      "metadata": {
        "id": "x2wR1bUMpVub"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Human vs Computer"
      ],
      "metadata": {
        "id": "1X-bLRh2ooUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# play with human\n",
        "p1 = Player(\"computer\", exp_rate=0)\n",
        "p1.loadPolicy(\"policy_p1\")\n",
        "\n",
        "p2 = HumanPlayer(\"human\")\n",
        "\n",
        "st = State(p1, p2)\n",
        "st.play2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2LmtgmJoaaG",
        "outputId": "99a9e6ca-4eed-42f7-f67f-f251b58d5531"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "Input your action row:0\n",
            "Input your action col:2\n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "| x |   | x | \n",
            "-------------\n",
            "Input your action row:2\n",
            "Input your action col:1\n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "Input your action row:1\n",
            "Input your action col:1\n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "Input your action row:0\n",
            "Input your action col:1\n",
            "-------------\n",
            "| x | o | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "human wins!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When the agent learns to play against a random fixed opponent\n",
        "\n"
      ],
      "metadata": {
        "id": "lEO5F3o_FTho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "    def __init__(self, p1, p2):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.p1 = p1\n",
        "        self.p2 = p2\n",
        "        self.isEnd = False\n",
        "        self.boardHash = None\n",
        "        # init p1 plays first\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    # get unique hash of current board state\n",
        "    def getHash(self):\n",
        "        self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return self.boardHash\n",
        "\n",
        "    def winner(self):\n",
        "        # row\n",
        "        for i in range(BOARD_ROWS):\n",
        "            if sum(self.board[i, :]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[i, :]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # col\n",
        "        for i in range(BOARD_COLS):\n",
        "            if sum(self.board[:, i]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[:, i]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # diagonal\n",
        "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
        "        diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)])\n",
        "        diag_sum = max(abs(diag_sum1), abs(diag_sum2))\n",
        "        if diag_sum == 3:\n",
        "            self.isEnd = True\n",
        "            if diag_sum1 == 3 or diag_sum2 == 3:\n",
        "                return 1\n",
        "            else:\n",
        "                return -1\n",
        "\n",
        "        # tie\n",
        "        # no available positions\n",
        "        if len(self.availablePositions()) == 0:\n",
        "            self.isEnd = True\n",
        "            return 0\n",
        "        # not end\n",
        "        self.isEnd = False\n",
        "        return None\n",
        "\n",
        "    def availablePositions(self):\n",
        "        positions = []\n",
        "        for i in range(BOARD_ROWS):\n",
        "            for j in range(BOARD_COLS):\n",
        "                if self.board[i, j] == 0:\n",
        "                    positions.append((i, j))  # need to be tuple\n",
        "        return positions\n",
        "\n",
        "    def updateState(self, position):\n",
        "        self.board[position] = self.playerSymbol\n",
        "        # switch to another player\n",
        "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
        "\n",
        "    # only when game ends\n",
        "    def giveReward(self):\n",
        "        result = self.winner()\n",
        "        # backpropagate reward\n",
        "        if result == 1:\n",
        "            self.p1.feedReward(1)\n",
        "            self.p2.feedReward(0)\n",
        "        elif result == -1:\n",
        "            self.p1.feedReward(0)\n",
        "            self.p2.feedReward(1)\n",
        "        else:\n",
        "            self.p1.feedReward(0.1)\n",
        "            self.p2.feedReward(0.5)\n",
        "\n",
        "    # board reset\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.boardHash = None\n",
        "        self.isEnd = False\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    def play(self, rounds=100):\n",
        "        for i in range(rounds):\n",
        "            if i % 1000 == 0:\n",
        "                print(\"Rounds {}\".format(i))\n",
        "            while not self.isEnd:\n",
        "                # Player 1\n",
        "                positions = self.availablePositions()\n",
        "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                # take action and upate board state\n",
        "                self.updateState(p1_action)\n",
        "                board_hash = self.getHash()\n",
        "                self.p1.addState(board_hash)\n",
        "                # check board status if it is end\n",
        "\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    # self.showBoard()\n",
        "                    # ended with p1 either win or draw\n",
        "                    self.giveReward()\n",
        "                    self.p1.reset()\n",
        "                    self.p2.reset()\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "                else:\n",
        "                    # Player 2\n",
        "                    positions = self.availablePositions()\n",
        "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                    # idx = np.random.choice(len(positions))\n",
        "                    # p2_action = positions[idx]\n",
        "                    self.updateState(p2_action)\n",
        "                    board_hash = self.getHash()\n",
        "                    self.p2.addState(board_hash)\n",
        "\n",
        "                    win = self.winner()\n",
        "                    if win is not None:\n",
        "                        # self.showBoard()\n",
        "                        # ended with p2 either win or draw\n",
        "                        self.giveReward()\n",
        "                        self.p1.reset()\n",
        "                        self.p2.reset()\n",
        "                        self.reset()\n",
        "                        break\n",
        "\n",
        "    # play with human\n",
        "    def play2(self):\n",
        "        while not self.isEnd:\n",
        "            # Player 1\n",
        "            positions = self.availablePositions()\n",
        "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "            # take action and upate board state\n",
        "            self.updateState(p1_action)\n",
        "            self.showBoard()\n",
        "            # check board status if it is end\n",
        "            win = self.winner()\n",
        "            if win is not None:\n",
        "                if win == 1:\n",
        "                    print(self.p1.name, \"wins!\")\n",
        "                else:\n",
        "                    print(\"tie!\")\n",
        "                self.reset()\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                # Player 2\n",
        "                positions = self.availablePositions()\n",
        "                p2_action = self.p2.chooseAction(positions)\n",
        "\n",
        "                self.updateState(p2_action)\n",
        "                self.showBoard()\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    if win == -1:\n",
        "                        print(self.p2.name, \"wins!\")\n",
        "                    else:\n",
        "                        print(\"tie!\")\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "    def showBoard(self):\n",
        "        # p1: x  p2: o\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            print('-------------')\n",
        "            out = '| '\n",
        "            for j in range(0, BOARD_COLS):\n",
        "                if self.board[i, j] == 1:\n",
        "                    token = 'x'\n",
        "                if self.board[i, j] == -1:\n",
        "                    token = 'o'\n",
        "                if self.board[i, j] == 0:\n",
        "                    token = ' '\n",
        "                out += token + ' | '\n",
        "            print(out)\n",
        "        print('-------------')"
      ],
      "metadata": {
        "id": "wTOVJIaBHUkU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Player:\n",
        "\n",
        "    def __init__(self, name, exp_rate=0.3):\n",
        "        self.name = name\n",
        "        self.states = []  # record all positions taken\n",
        "        self.lr = 0.2\n",
        "        self.exp_rate = exp_rate\n",
        "        self.decay_gamma = 0.9\n",
        "        self.states_value = {}  # state -> value\n",
        "        self.exp_choice = 0\n",
        "\n",
        "    def getHash(self, board):\n",
        "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return boardHash\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        self.exp_choice = np.random.uniform(0, 1)\n",
        "        if self.exp_choice <= self.exp_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(positions))\n",
        "            action = positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for p in positions:\n",
        "                next_board = current_board.copy()\n",
        "                next_board[p] = symbol\n",
        "                next_boardHash = self.getHash(next_board)\n",
        "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
        "                # print(\"value\", value)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = p\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        self.states.append(state)\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        for st in reversed(self.states):\n",
        "            if self.states_value.get(st) is None:\n",
        "                self.states_value[st] = 0\n",
        "            if self.exp_choice >= self.exp_rate:\n",
        "                self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
        "            reward = self.states_value[st]\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "\n",
        "    def savePolicy(self):\n",
        "        fw = open('policy_' + str(self.name), 'wb')\n",
        "        pickle.dump(self.states_value, fw)\n",
        "        fw.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        fr = open(file, 'rb')\n",
        "        self.states_value = pickle.load(fr)\n",
        "        fr.close()\n",
        "\n",
        "\n",
        "class Player2:\n",
        "\n",
        "    def __init__(self, name, exp_rate=0):\n",
        "        self.name = name\n",
        "        self.states = []  # record all positions taken\n",
        "        # self.lr = 0.2\n",
        "        self.exp_rate = exp_rate\n",
        "        # self.decay_gamma = 0.9\n",
        "        self.states_value = {}  # state -> value\n",
        "        self.exp_choice = 0\n",
        "\n",
        "    def getHash(self, board):\n",
        "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return boardHash\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        self.exp_choice = np.random.uniform(0, 1)\n",
        "        if self.exp_choice <= self.exp_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(positions))\n",
        "            action = positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for p in positions:\n",
        "                next_board = current_board.copy()\n",
        "                next_board[p] = symbol\n",
        "                next_boardHash = self.getHash(next_board)\n",
        "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
        "                # print(\"value\", value)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = p\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        # self.states.append(state)\n",
        "        pass\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        # for st in reversed(self.states):\n",
        "        #     if self.states_value.get(st) is None:\n",
        "        #         self.states_value[st] = 0\n",
        "        #     if self.exp_choice >= self.exp_rate:\n",
        "        #         self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
        "        #     reward = self.states_value[st]\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        # self.states = []\n",
        "        pass\n",
        "\n",
        "    # def savePolicy(self):\n",
        "    #     fw = open('policy_' + str(self.name), 'wb')\n",
        "    #     pickle.dump(self.states_value, fw)\n",
        "    #     fw.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        fr = open(file, 'rb')\n",
        "        self.states_value = pickle.load(fr)\n",
        "        fr.close()\n"
      ],
      "metadata": {
        "id": "paREpKbWRQ9b"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HumanPlayer:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def chooseAction(self, positions):\n",
        "        while True:\n",
        "            row = int(input(\"Input your action row:\"))\n",
        "            col = int(input(\"Input your action col:\"))\n",
        "            action = (row, col)\n",
        "            if action in positions:\n",
        "                return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        pass\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # training\n",
        "    p1 = Player(\"p1\")\n",
        "    p2 = Player2(\"computer\", exp_rate=0)\n",
        "    p2.loadPolicy(\"policy_p1\")\n",
        "\n",
        "    st = State(p1, p2)\n",
        "    print(\"training...\")\n",
        "    st.play(10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWSdvh-0IPm3",
        "outputId": "27cc8201-ac1d-4b2c-815c-3524353a45a0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n",
            "Rounds 0\n",
            "Rounds 1000\n",
            "Rounds 2000\n",
            "Rounds 3000\n",
            "Rounds 4000\n",
            "Rounds 5000\n",
            "Rounds 6000\n",
            "Rounds 7000\n",
            "Rounds 8000\n",
            "Rounds 9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1.savePolicy()\n",
        "p1.loadPolicy(\"policy_p1\")"
      ],
      "metadata": {
        "id": "h-Yw481cJDMv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# play with human\n",
        "p1 = Player(\"computer\", exp_rate=0)\n",
        "p1.loadPolicy(\"policy_p1\")\n",
        "\n",
        "p2 = HumanPlayer(\"human\")\n",
        "\n",
        "st = State(p1, p2)\n",
        "st.play2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaBenwezIuD4",
        "outputId": "fda08d70-0bc1-47be-8499-d576afdf1426"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "Input your action row:1\n",
            "Input your action col:1\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "| x |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "Input your action row:0\n",
            "Input your action col:2\n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "|   | x | x | \n",
            "-------------\n",
            "Input your action row:2\n",
            "Input your action col:0\n",
            "-------------\n",
            "| x |   | o | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "human wins!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When the agent learns to play against itself"
      ],
      "metadata": {
        "id": "l6Rmf-6tKPin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "    def __init__(self, p1, p2):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.p1 = p1\n",
        "        self.p2 = p2\n",
        "        self.isEnd = False\n",
        "        self.boardHash = None\n",
        "        # init p1 plays first\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    # get unique hash of current board state\n",
        "    def getHash(self):\n",
        "        self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return self.boardHash\n",
        "\n",
        "    def winner(self):\n",
        "        # row\n",
        "        for i in range(BOARD_ROWS):\n",
        "            if sum(self.board[i, :]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[i, :]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # col\n",
        "        for i in range(BOARD_COLS):\n",
        "            if sum(self.board[:, i]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[:, i]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # diagonal\n",
        "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
        "        diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)])\n",
        "        diag_sum = max(abs(diag_sum1), abs(diag_sum2))\n",
        "        if diag_sum == 3:\n",
        "            self.isEnd = True\n",
        "            if diag_sum1 == 3 or diag_sum2 == 3:\n",
        "                return 1\n",
        "            else:\n",
        "                return -1\n",
        "\n",
        "        # tie\n",
        "        # no available positions\n",
        "        if len(self.availablePositions()) == 0:\n",
        "            self.isEnd = True\n",
        "            return 0\n",
        "        # not end\n",
        "        self.isEnd = False\n",
        "        return None\n",
        "\n",
        "    def availablePositions(self):\n",
        "        positions = []\n",
        "        for i in range(BOARD_ROWS):\n",
        "            for j in range(BOARD_COLS):\n",
        "                if self.board[i, j] == 0:\n",
        "                    positions.append((i, j))  # need to be tuple\n",
        "        return positions\n",
        "\n",
        "    def updateState(self, position):\n",
        "        self.board[position] = self.playerSymbol\n",
        "        # switch to another player\n",
        "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
        "\n",
        "    # only when game ends\n",
        "    def giveReward(self):\n",
        "        result = self.winner()\n",
        "        # backpropagate reward\n",
        "        if result == 1:\n",
        "            self.p1.feedReward(1)\n",
        "            self.p2.feedReward(0)\n",
        "        elif result == -1:\n",
        "            self.p1.feedReward(0)\n",
        "            self.p2.feedReward(1)\n",
        "        else:\n",
        "            self.p1.feedReward(0.1)\n",
        "            self.p2.feedReward(0.1)\n",
        "\n",
        "    # board reset\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.boardHash = None\n",
        "        self.isEnd = False\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    def play(self, rounds=100):\n",
        "        for i in range(rounds):\n",
        "            if i % 1000 == 0:\n",
        "                print(\"Rounds {}\".format(i))\n",
        "            while not self.isEnd:\n",
        "                # Player 1\n",
        "                positions = self.availablePositions()\n",
        "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                # take action and upate board state\n",
        "                self.updateState(p1_action)\n",
        "                board_hash = self.getHash()\n",
        "                self.p1.addState(board_hash)\n",
        "                # check board status if it is end\n",
        "\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    # self.showBoard()\n",
        "                    # ended with p1 either win or draw\n",
        "                    self.giveReward()\n",
        "                    self.p1.reset()\n",
        "                    self.p2.reset()\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "                else:\n",
        "                    # Player 2\n",
        "                    positions = self.availablePositions()\n",
        "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                    # idx = np.random.choice(len(positions))\n",
        "                    # p2_action = positions[idx]\n",
        "                    self.updateState(p2_action)\n",
        "                    board_hash = self.getHash()\n",
        "                    self.p2.addState(board_hash)\n",
        "\n",
        "                    win = self.winner()\n",
        "                    if win is not None:\n",
        "                        # self.showBoard()\n",
        "                        # ended with p2 either win or draw\n",
        "                        self.giveReward()\n",
        "                        self.p1.reset()\n",
        "                        self.p2.reset()\n",
        "                        self.reset()\n",
        "                        break\n",
        "\n",
        "    # play with human\n",
        "    def play2(self):\n",
        "        while not self.isEnd:\n",
        "            # Player 1\n",
        "            positions = self.availablePositions()\n",
        "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "            # take action and upate board state\n",
        "            self.updateState(p1_action)\n",
        "            self.showBoard()\n",
        "            # check board status if it is end\n",
        "            win = self.winner()\n",
        "            if win is not None:\n",
        "                if win == 1:\n",
        "                    print(self.p1.name, \"wins!\")\n",
        "                else:\n",
        "                    print(\"tie!\")\n",
        "                self.reset()\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                # Player 2\n",
        "                positions = self.availablePositions()\n",
        "                p2_action = self.p2.chooseAction(positions)\n",
        "                # p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
        "\n",
        "                self.updateState(p2_action)\n",
        "                self.showBoard()\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    if win == -1:\n",
        "                        print(self.p2.name, \"wins!\")\n",
        "                    else:\n",
        "                        print(\"tie!\")\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "    def showBoard(self):\n",
        "        # p1: x  p2: o\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            print('-------------')\n",
        "            out = '| '\n",
        "            for j in range(0, BOARD_COLS):\n",
        "                if self.board[i, j] == 1:\n",
        "                    token = 'x'\n",
        "                if self.board[i, j] == -1:\n",
        "                    token = 'o'\n",
        "                if self.board[i, j] == 0:\n",
        "                    token = ' '\n",
        "                out += token + ' | '\n",
        "            print(out)\n",
        "        print('-------------')"
      ],
      "metadata": {
        "id": "tvelTBxvKOls"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Player:\n",
        "\n",
        "    def __init__(self, name, exp_rate=0.3):\n",
        "        self.name = name\n",
        "        self.states = []  # record all positions taken\n",
        "        self.lr = 0.2\n",
        "        self.exp_rate = exp_rate\n",
        "        self.decay_gamma = 0.9\n",
        "        self.states_value = {}  # state -> value\n",
        "        self.exp_choice = 0\n",
        "\n",
        "    def getHash(self, board):\n",
        "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return boardHash\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        self.exp_choice = np.random.uniform(0, 1)\n",
        "        if self.exp_choice <= self.exp_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(positions))\n",
        "            action = positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for p in positions:\n",
        "                next_board = current_board.copy()\n",
        "                next_board[p] = symbol\n",
        "                next_boardHash = self.getHash(next_board)\n",
        "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
        "                # print(\"value\", value)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = p\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        self.states.append(state)\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        for st in reversed(self.states):\n",
        "            if self.states_value.get(st) is None:\n",
        "                self.states_value[st] = 0\n",
        "            if self.exp_choice >= self.exp_rate:\n",
        "                self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
        "            reward = self.states_value[st]\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "\n",
        "    def savePolicy(self):\n",
        "        fw = open('policy_' + str(self.name), 'wb')\n",
        "        pickle.dump(self.states_value, fw)\n",
        "        fw.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        fr = open(file, 'rb')\n",
        "        self.states_value = pickle.load(fr)\n",
        "        fr.close()\n"
      ],
      "metadata": {
        "id": "xCksRDjvOITM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HumanPlayer:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def chooseAction(self, positions):\n",
        "        while True:\n",
        "            row = int(input(\"Input your action row:\"))\n",
        "            col = int(input(\"Input your action col:\"))\n",
        "            action = (row, col)\n",
        "            if action in positions:\n",
        "                return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        pass\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # training\n",
        "    p1 = Player(\"p1\")\n",
        "    p2 = Player(\"p1\")\n",
        "\n",
        "    st = State(p1, p2)\n",
        "    print(\"training...\")\n",
        "    st.play(10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAsOukTiLiMx",
        "outputId": "cd74a12e-eaa5-4bec-f83e-a8cd99ce9be6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n",
            "Rounds 0\n",
            "Rounds 1000\n",
            "Rounds 2000\n",
            "Rounds 3000\n",
            "Rounds 4000\n",
            "Rounds 5000\n",
            "Rounds 6000\n",
            "Rounds 7000\n",
            "Rounds 8000\n",
            "Rounds 9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1.savePolicy()\n",
        "p1.loadPolicy(\"policy_p1\")"
      ],
      "metadata": {
        "id": "XfzdGyhrLtjW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# play with human\n",
        "p1 = Player(\"computer\", exp_rate=0)\n",
        "p1.loadPolicy(\"policy_p1\")\n",
        "\n",
        "p2 = HumanPlayer(\"human\")\n",
        "\n",
        "st = State(p1, p2)\n",
        "st.play2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwHZe6wrLuWg",
        "outputId": "642fe105-2c83-4f9a-faa4-72370bc54af8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "Input your action row:1\n",
            "Input your action col:1\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "Input your action row:0\n",
            "Input your action col:2\n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| x |   | x | \n",
            "-------------\n",
            "Input your action row:2\n",
            "Input your action col:1\n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "-------------\n",
            "|   | x | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "Input your action row:0\n",
            "Input your action col:0\n",
            "-------------\n",
            "| o | x | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "-------------\n",
            "| o | x | o | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "| x | o | x | \n",
            "-------------\n",
            "tie!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Greedy agent, agent that trains without exploring"
      ],
      "metadata": {
        "id": "53z6Cs_MY0cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "    def __init__(self, p1, p2):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.p1 = p1\n",
        "        self.p2 = p2\n",
        "        self.isEnd = False\n",
        "        self.boardHash = None\n",
        "        # init p1 plays first\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    # get unique hash of current board state\n",
        "    def getHash(self):\n",
        "        self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return self.boardHash\n",
        "\n",
        "    def winner(self):\n",
        "        # row\n",
        "        for i in range(BOARD_ROWS):\n",
        "            if sum(self.board[i, :]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[i, :]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # col\n",
        "        for i in range(BOARD_COLS):\n",
        "            if sum(self.board[:, i]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[:, i]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # diagonal\n",
        "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
        "        diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)])\n",
        "        diag_sum = max(abs(diag_sum1), abs(diag_sum2))\n",
        "        if diag_sum == 3:\n",
        "            self.isEnd = True\n",
        "            if diag_sum1 == 3 or diag_sum2 == 3:\n",
        "                return 1\n",
        "            else:\n",
        "                return -1\n",
        "\n",
        "        # tie\n",
        "        # no available positions\n",
        "        if len(self.availablePositions()) == 0:\n",
        "            self.isEnd = True\n",
        "            return 0\n",
        "        # not end\n",
        "        self.isEnd = False\n",
        "        return None\n",
        "\n",
        "    def availablePositions(self):\n",
        "        positions = []\n",
        "        for i in range(BOARD_ROWS):\n",
        "            for j in range(BOARD_COLS):\n",
        "                if self.board[i, j] == 0:\n",
        "                    positions.append((i, j))  # need to be tuple\n",
        "        return positions\n",
        "\n",
        "    def updateState(self, position):\n",
        "        self.board[position] = self.playerSymbol\n",
        "        # switch to another player\n",
        "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
        "\n",
        "    # only when game ends\n",
        "    def giveReward(self):\n",
        "        result = self.winner()\n",
        "        # backpropagate reward\n",
        "        if result == 1:\n",
        "            self.p1.feedReward(1)\n",
        "            self.p2.feedReward(0)\n",
        "        elif result == -1:\n",
        "            self.p1.feedReward(0)\n",
        "            self.p2.feedReward(1)\n",
        "        else:\n",
        "            self.p1.feedReward(0.1)\n",
        "            self.p2.feedReward(0.5)\n",
        "\n",
        "    # board reset\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.boardHash = None\n",
        "        self.isEnd = False\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    def play(self, rounds=100):\n",
        "        for i in range(rounds):\n",
        "            if i % 1000 == 0:\n",
        "                print(\"Rounds {}\".format(i))\n",
        "            while not self.isEnd:\n",
        "                # Player 1\n",
        "                positions = self.availablePositions()\n",
        "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                # take action and upate board state\n",
        "                self.updateState(p1_action)\n",
        "                board_hash = self.getHash()\n",
        "                self.p1.addState(board_hash)\n",
        "                # check board status if it is end\n",
        "\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    # self.showBoard()\n",
        "                    # ended with p1 either win or draw\n",
        "                    self.giveReward()\n",
        "                    self.p1.reset()\n",
        "                    self.p2.reset()\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "                else:\n",
        "                    # Player 2\n",
        "                    positions = self.availablePositions()\n",
        "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                    # idx = np.random.choice(len(positions))\n",
        "                    # p2_action = positions[idx]\n",
        "                    self.updateState(p2_action)\n",
        "                    board_hash = self.getHash()\n",
        "                    self.p2.addState(board_hash)\n",
        "\n",
        "                    win = self.winner()\n",
        "                    if win is not None:\n",
        "                        # self.showBoard()\n",
        "                        # ended with p2 either win or draw\n",
        "                        self.giveReward()\n",
        "                        self.p1.reset()\n",
        "                        self.p2.reset()\n",
        "                        self.reset()\n",
        "                        break\n",
        "\n",
        "    # play with human\n",
        "    def play2(self):\n",
        "        while not self.isEnd:\n",
        "            # Player 1\n",
        "            positions = self.availablePositions()\n",
        "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "            # take action and upate board state\n",
        "            self.updateState(p1_action)\n",
        "            self.showBoard()\n",
        "            # check board status if it is end\n",
        "            win = self.winner()\n",
        "            if win is not None:\n",
        "                if win == 1:\n",
        "                    print(self.p1.name, \"wins!\")\n",
        "                else:\n",
        "                    print(\"tie!\")\n",
        "                self.reset()\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                # Player 2\n",
        "                positions = self.availablePositions()\n",
        "                p2_action = self.p2.chooseAction(positions)\n",
        "\n",
        "                self.updateState(p2_action)\n",
        "                self.showBoard()\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    if win == -1:\n",
        "                        print(self.p2.name, \"wins!\")\n",
        "                    else:\n",
        "                        print(\"tie!\")\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "    def showBoard(self):\n",
        "        # p1: x  p2: o\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            print('-------------')\n",
        "            out = '| '\n",
        "            for j in range(0, BOARD_COLS):\n",
        "                if self.board[i, j] == 1:\n",
        "                    token = 'x'\n",
        "                if self.board[i, j] == -1:\n",
        "                    token = 'o'\n",
        "                if self.board[i, j] == 0:\n",
        "                    token = ' '\n",
        "                out += token + ' | '\n",
        "            print(out)\n",
        "        print('-------------')"
      ],
      "metadata": {
        "id": "rS_ztHlYZCLf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Player:\n",
        "\n",
        "    def __init__(self, name, exp_rate=0):\n",
        "        self.name = name\n",
        "        self.states = []  # record all positions taken\n",
        "        self.lr = 0.2\n",
        "        self.exp_rate = exp_rate\n",
        "        self.decay_gamma = 0.9\n",
        "        self.states_value = {}  # state -> value\n",
        "        self.exp_choice = 0\n",
        "\n",
        "    def getHash(self, board):\n",
        "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return boardHash\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        self.exp_choice = np.random.uniform(0, 1)\n",
        "        if self.exp_choice <= self.exp_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(positions))\n",
        "            action = positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for p in positions:\n",
        "                next_board = current_board.copy()\n",
        "                next_board[p] = symbol\n",
        "                next_boardHash = self.getHash(next_board)\n",
        "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
        "                # print(\"value\", value)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = p\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        self.states.append(state)\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        for st in reversed(self.states):\n",
        "            if self.states_value.get(st) is None:\n",
        "                self.states_value[st] = 0\n",
        "            if self.exp_choice >= self.exp_rate:\n",
        "                self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
        "            reward = self.states_value[st]\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "\n",
        "    def savePolicy(self):\n",
        "        fw = open('policy_' + str(self.name), 'wb')\n",
        "        pickle.dump(self.states_value, fw)\n",
        "        fw.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        fr = open(file, 'rb')\n",
        "        self.states_value = pickle.load(fr)\n",
        "        fr.close()\n",
        "\n",
        "\n",
        "class Player2:\n",
        "\n",
        "    def __init__(self, name, exp_rate=0):\n",
        "        self.name = name\n",
        "        self.states = []  # record all positions taken\n",
        "        # self.lr = 0.2\n",
        "        self.exp_rate = exp_rate\n",
        "        # self.decay_gamma = 0.9\n",
        "        self.states_value = {}  # state -> value\n",
        "        self.exp_choice = 0\n",
        "\n",
        "    def getHash(self, board):\n",
        "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return boardHash\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        self.exp_choice = np.random.uniform(0, 1)\n",
        "        if self.exp_choice <= self.exp_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(positions))\n",
        "            action = positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for p in positions:\n",
        "                next_board = current_board.copy()\n",
        "                next_board[p] = symbol\n",
        "                next_boardHash = self.getHash(next_board)\n",
        "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
        "                # print(\"value\", value)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = p\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        # self.states.append(state)\n",
        "        pass\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        # for st in reversed(self.states):\n",
        "        #     if self.states_value.get(st) is None:\n",
        "        #         self.states_value[st] = 0\n",
        "        #     if self.exp_choice >= self.exp_rate:\n",
        "        #         self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
        "        #     reward = self.states_value[st]\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        # self.states = []\n",
        "        pass\n",
        "\n",
        "    # def savePolicy(self):\n",
        "    #     fw = open('policy_' + str(self.name), 'wb')\n",
        "    #     pickle.dump(self.states_value, fw)\n",
        "    #     fw.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        fr = open(file, 'rb')\n",
        "        self.states_value = pickle.load(fr)\n",
        "        fr.close()\n"
      ],
      "metadata": {
        "id": "5B_9nRfwZCLg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HumanPlayer:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def chooseAction(self, positions):\n",
        "        while True:\n",
        "            row = int(input(\"Input your action row:\"))\n",
        "            col = int(input(\"Input your action col:\"))\n",
        "            action = (row, col)\n",
        "            if action in positions:\n",
        "                return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        pass\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # training\n",
        "    p1 = Player(\"p1\")\n",
        "    p2 = Player2(\"computer\", exp_rate=0)\n",
        "    p2.loadPolicy(\"policy_p1\")\n",
        "\n",
        "    st = State(p1, p2)\n",
        "    print(\"training...\")\n",
        "    st.play(10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8ebad2-0ba4-4801-ead0-d0a001973ef5",
        "id": "mNzd_PasZCLg"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n",
            "Rounds 0\n",
            "Rounds 1000\n",
            "Rounds 2000\n",
            "Rounds 3000\n",
            "Rounds 4000\n",
            "Rounds 5000\n",
            "Rounds 6000\n",
            "Rounds 7000\n",
            "Rounds 8000\n",
            "Rounds 9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1.savePolicy()\n",
        "p1.loadPolicy(\"policy_p1\")"
      ],
      "metadata": {
        "id": "rVsSR0aUZCLg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# play with human\n",
        "p1 = Player(\"computer\", exp_rate=0)\n",
        "p1.loadPolicy(\"policy_p1\")\n",
        "\n",
        "p2 = HumanPlayer(\"human\")\n",
        "\n",
        "st = State(p1, p2)\n",
        "st.play2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35f4205-d9a3-4a24-adea-f0b190b5fe9f",
        "id": "wf_VAXRzZCLh"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "Input your action row:1\n",
            "Input your action col:1\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "|   | x | x | \n",
            "-------------\n",
            "Input your action row:2\n",
            "Input your action col:0\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "Input your action row:0\n",
            "Input your action col:2\n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "human wins!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning from both exploration and exploitation"
      ],
      "metadata": {
        "id": "sEEfojkuasB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "    def __init__(self, p1, p2):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.p1 = p1\n",
        "        self.p2 = p2\n",
        "        self.isEnd = False\n",
        "        self.boardHash = None\n",
        "        # init p1 plays first\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    # get unique hash of current board state\n",
        "    def getHash(self):\n",
        "        self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return self.boardHash\n",
        "\n",
        "    def winner(self):\n",
        "        # row\n",
        "        for i in range(BOARD_ROWS):\n",
        "            if sum(self.board[i, :]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[i, :]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # col\n",
        "        for i in range(BOARD_COLS):\n",
        "            if sum(self.board[:, i]) == 3:\n",
        "                self.isEnd = True\n",
        "                return 1\n",
        "            if sum(self.board[:, i]) == -3:\n",
        "                self.isEnd = True\n",
        "                return -1\n",
        "        # diagonal\n",
        "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
        "        diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)])\n",
        "        diag_sum = max(abs(diag_sum1), abs(diag_sum2))\n",
        "        if diag_sum == 3:\n",
        "            self.isEnd = True\n",
        "            if diag_sum1 == 3 or diag_sum2 == 3:\n",
        "                return 1\n",
        "            else:\n",
        "                return -1\n",
        "\n",
        "        # tie\n",
        "        # no available positions\n",
        "        if len(self.availablePositions()) == 0:\n",
        "            self.isEnd = True\n",
        "            return 0\n",
        "        # not end\n",
        "        self.isEnd = False\n",
        "        return None\n",
        "\n",
        "    def availablePositions(self):\n",
        "        positions = []\n",
        "        for i in range(BOARD_ROWS):\n",
        "            for j in range(BOARD_COLS):\n",
        "                if self.board[i, j] == 0:\n",
        "                    positions.append((i, j))  # need to be tuple\n",
        "        return positions\n",
        "\n",
        "    def updateState(self, position):\n",
        "        self.board[position] = self.playerSymbol\n",
        "        # switch to another player\n",
        "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
        "\n",
        "    # only when game ends\n",
        "    def giveReward(self):\n",
        "        result = self.winner()\n",
        "        # backpropagate reward\n",
        "        if result == 1:\n",
        "            self.p1.feedReward(1)\n",
        "            self.p2.feedReward(0)\n",
        "        elif result == -1:\n",
        "            self.p1.feedReward(0)\n",
        "            self.p2.feedReward(1)\n",
        "        else:\n",
        "            self.p1.feedReward(0.1)\n",
        "            self.p2.feedReward(0.5)\n",
        "\n",
        "    # board reset\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.boardHash = None\n",
        "        self.isEnd = False\n",
        "        self.playerSymbol = 1\n",
        "\n",
        "    def play(self, rounds=100):\n",
        "        for i in range(rounds):\n",
        "            if i % 1000 == 0:\n",
        "                print(\"Rounds {}\".format(i))\n",
        "            while not self.isEnd:\n",
        "                # Player 1\n",
        "                positions = self.availablePositions()\n",
        "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                # take action and upate board state\n",
        "                self.updateState(p1_action)\n",
        "                board_hash = self.getHash()\n",
        "                self.p1.addState(board_hash)\n",
        "                # check board status if it is end\n",
        "\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    # self.showBoard()\n",
        "                    # ended with p1 either win or draw\n",
        "                    self.giveReward()\n",
        "                    self.p1.reset()\n",
        "                    self.p2.reset()\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "                else:\n",
        "                    # Player 2\n",
        "                    positions = self.availablePositions()\n",
        "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
        "                    # idx = np.random.choice(len(positions))\n",
        "                    # p2_action = positions[idx]\n",
        "                    self.updateState(p2_action)\n",
        "                    board_hash = self.getHash()\n",
        "                    self.p2.addState(board_hash)\n",
        "\n",
        "                    win = self.winner()\n",
        "                    if win is not None:\n",
        "                        # self.showBoard()\n",
        "                        # ended with p2 either win or draw\n",
        "                        self.giveReward()\n",
        "                        self.p1.reset()\n",
        "                        self.p2.reset()\n",
        "                        self.reset()\n",
        "                        break\n",
        "\n",
        "    # play with human\n",
        "    def play2(self):\n",
        "        while not self.isEnd:\n",
        "            # Player 1\n",
        "            positions = self.availablePositions()\n",
        "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
        "            # take action and upate board state\n",
        "            self.updateState(p1_action)\n",
        "            self.showBoard()\n",
        "            # check board status if it is end\n",
        "            win = self.winner()\n",
        "            if win is not None:\n",
        "                if win == 1:\n",
        "                    print(self.p1.name, \"wins!\")\n",
        "                else:\n",
        "                    print(\"tie!\")\n",
        "                self.reset()\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                # Player 2\n",
        "                positions = self.availablePositions()\n",
        "                p2_action = self.p2.chooseAction(positions)\n",
        "\n",
        "                self.updateState(p2_action)\n",
        "                self.showBoard()\n",
        "                win = self.winner()\n",
        "                if win is not None:\n",
        "                    if win == -1:\n",
        "                        print(self.p2.name, \"wins!\")\n",
        "                    else:\n",
        "                        print(\"tie!\")\n",
        "                    self.reset()\n",
        "                    break\n",
        "\n",
        "    def showBoard(self):\n",
        "        # p1: x  p2: o\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            print('-------------')\n",
        "            out = '| '\n",
        "            for j in range(0, BOARD_COLS):\n",
        "                if self.board[i, j] == 1:\n",
        "                    token = 'x'\n",
        "                if self.board[i, j] == -1:\n",
        "                    token = 'o'\n",
        "                if self.board[i, j] == 0:\n",
        "                    token = ' '\n",
        "                out += token + ' | '\n",
        "            print(out)\n",
        "        print('-------------')"
      ],
      "metadata": {
        "id": "jtw2z8I9ayQA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Player:\n",
        "\n",
        "    def __init__(self, name, exp_rate=0.3):\n",
        "        self.name = name\n",
        "        self.states = []  # record all positions taken\n",
        "        self.lr = 0.2\n",
        "        self.exp_rate = exp_rate\n",
        "        self.decay_gamma = 0.9\n",
        "        self.states_value = {}  # state -> value\n",
        "        self.exp_choice = 0\n",
        "\n",
        "    def getHash(self, board):\n",
        "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return boardHash\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        self.exp_choice = np.random.uniform(0, 1)\n",
        "        if self.exp_choice <= self.exp_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(positions))\n",
        "            action = positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for p in positions:\n",
        "                next_board = current_board.copy()\n",
        "                next_board[p] = symbol\n",
        "                next_boardHash = self.getHash(next_board)\n",
        "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
        "                # print(\"value\", value)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = p\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        self.states.append(state)\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        for st in reversed(self.states):\n",
        "            if self.states_value.get(st) is None:\n",
        "                self.states_value[st] = 0\n",
        "            # if self.exp_choice >= self.exp_rate:\n",
        "            self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
        "            reward = self.states_value[st]\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "\n",
        "    def savePolicy(self):\n",
        "        fw = open('policy_' + str(self.name), 'wb')\n",
        "        pickle.dump(self.states_value, fw)\n",
        "        fw.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        fr = open(file, 'rb')\n",
        "        self.states_value = pickle.load(fr)\n",
        "        fr.close()\n",
        "\n",
        "\n",
        "class Player2:\n",
        "\n",
        "    def __init__(self, name, exp_rate=0):\n",
        "        self.name = name\n",
        "        self.states = []  # record all positions taken\n",
        "        # self.lr = 0.2\n",
        "        self.exp_rate = exp_rate\n",
        "        # self.decay_gamma = 0.9\n",
        "        self.states_value = {}  # state -> value\n",
        "        self.exp_choice = 0\n",
        "\n",
        "    def getHash(self, board):\n",
        "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
        "        return boardHash\n",
        "\n",
        "    def chooseAction(self, positions, current_board, symbol):\n",
        "        self.exp_choice = np.random.uniform(0, 1)\n",
        "        if self.exp_choice <= self.exp_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(positions))\n",
        "            action = positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for p in positions:\n",
        "                next_board = current_board.copy()\n",
        "                next_board[p] = symbol\n",
        "                next_boardHash = self.getHash(next_board)\n",
        "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
        "                # print(\"value\", value)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = p\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        # self.states.append(state)\n",
        "        pass\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        # for st in reversed(self.states):\n",
        "        #     if self.states_value.get(st) is None:\n",
        "        #         self.states_value[st] = 0\n",
        "        #     if self.exp_choice >= self.exp_rate:\n",
        "        #         self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
        "        #     reward = self.states_value[st]\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        # self.states = []\n",
        "        pass\n",
        "\n",
        "    # def savePolicy(self):\n",
        "    #     fw = open('policy_' + str(self.name), 'wb')\n",
        "    #     pickle.dump(self.states_value, fw)\n",
        "    #     fw.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        fr = open(file, 'rb')\n",
        "        self.states_value = pickle.load(fr)\n",
        "        fr.close()\n"
      ],
      "metadata": {
        "id": "Ql1gcuAkayQB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HumanPlayer:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def chooseAction(self, positions):\n",
        "        while True:\n",
        "            row = int(input(\"Input your action row:\"))\n",
        "            col = int(input(\"Input your action col:\"))\n",
        "            action = (row, col)\n",
        "            if action in positions:\n",
        "                return action\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        pass\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # training\n",
        "    p1 = Player(\"p1\")\n",
        "    p2 = Player2(\"computer\", exp_rate=0)\n",
        "    p2.loadPolicy(\"policy_p1\")\n",
        "\n",
        "    st = State(p1, p2)\n",
        "    print(\"training...\")\n",
        "    st.play(10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbb577f-0a3b-4d52-9fd4-442337bb0c70",
        "id": "blhgOvMkayQC"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n",
            "Rounds 0\n",
            "Rounds 1000\n",
            "Rounds 2000\n",
            "Rounds 3000\n",
            "Rounds 4000\n",
            "Rounds 5000\n",
            "Rounds 6000\n",
            "Rounds 7000\n",
            "Rounds 8000\n",
            "Rounds 9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1.savePolicy()\n",
        "p1.loadPolicy(\"policy_p1\")"
      ],
      "metadata": {
        "id": "u9yk154BayQD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# play with human\n",
        "p1 = Player(\"computer\", exp_rate=0)\n",
        "p1.loadPolicy(\"policy_p1\")\n",
        "\n",
        "p2 = HumanPlayer(\"human\")\n",
        "\n",
        "st = State(p1, p2)\n",
        "st.play2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8a41c3-ae74-4b10-c761-7de141b252fa",
        "id": "thQPMIq_ayQD"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "Input your action row:1\n",
            "Input your action col:1\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "|   |   | x | \n",
            "-------------\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "|   | x | x | \n",
            "-------------\n",
            "Input your action row:2\n",
            "Input your action col:0\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o |   | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "-------------\n",
            "|   |   |   | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "Input your action row:0\n",
            "Input your action col:2\n",
            "-------------\n",
            "|   |   | o | \n",
            "-------------\n",
            "|   | o | x | \n",
            "-------------\n",
            "| o | x | x | \n",
            "-------------\n",
            "human wins!\n"
          ]
        }
      ]
    }
  ]
}